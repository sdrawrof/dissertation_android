![app1](https://user-images.githubusercontent.com/53451723/134715213-30ddd7a7-30aa-40fd-acfa-68cde1277d85.png)
![app2](https://user-images.githubusercontent.com/53451723/134715219-960bf184-7ada-46d5-9378-faff1dd283d2.png)
![architecture](https://user-images.githubusercontent.com/53451723/134715225-7fb2fdc4-9263-4576-8e01-b7cbc9e37f5d.png)
![lecture](https://user-images.githubusercontent.com/53451723/134715227-b56f84c2-7535-4f59-a97c-2006dadf47dd.png)
![lecture2](https://user-images.githubusercontent.com/53451723/134715229-1b616fae-3e27-4370-85e5-0a180b274e45.png)
![questions](https://user-images.githubusercontent.com/53451723/134715242-54652e72-a23d-4714-9467-4e192d422d44.png)
# Intelligent Voice based app for Revision using Automatic Question Generation #

The project consists of an Android app that uses Automatic Question Generation (AQG) techniques to aid its users with revision. Automatic Question Generation is a growing field of research that determines methods to construct questions from text, concepts maps, etc. This novel system is tailored to work effectively with lecture slides in particular, analysing the material and using complex linguistic rules and Natural Language Processing to form questions out of bullet pointed text. Ideally users would then be able to communicate with the app through voice based conversation and receive feedback on their answers, however this repository contains only the Android side, which demonstrates how the user can answer questions using their voice as well as upload documents from their device into the AQG system. The working Automatic Question Generation was developed seperately.

![Project Architecture](app/res/architecture.png "Project Architecture")

### Examples of lecture slides and the resulting questions generated ###

![Lecture 1](app/res/lecture2.PNG "Lecture 1")
![Lecture 2](app/res/lecture.PNG "Lecture 2")


Questions were produced at a grammatical coherency rate of up to 75%, with the percentage rising as the proportion of full sentences within the educational material increased.

Questions Generated:
![Questions Generated](app/res/questions.PNG "Questions Generated")


The Android app is a prototype demonstrating how users can be asked questions generated by the AQG methods. Users can answer using their voice which is then analysed to determine their answer's correctness, which is relayed back to the user. There are many opportunities for advancing the capabilites of the application, from user scoring to time-based testing.


![Android app](https://user-images.githubusercontent.com/53451723/134715219-960bf184-7ada-46d5-9378-faff1dd283d2.png "Asking Questions to the User")

[Download the android app here (requires permission to download applications from the internet to be set to allow on your device)] (https://drive.google.com/file/d/1wbWUuWVh60SvT9cQZEwZPfWvrpfj3eh5/view?usp=sharing)


The project was written in Java and Android development languages. In order to integrate the Automatic Question Generation system to the app a dedicated server must be set up in order to run a Natural Language Processing pipeline using jar files from Stanford's CoreNLP. This takes the text from the lecture slides and applies syntactic and semantic tags in order for the Automatic Question Generation system to identify how to convert the sentences into questions. In this repository this method is implemented manually using the Stanford CoreNLP libraries. This project was part of my undergraduate dissertation.

For more information please email a.macheny@outlook.com

Adia-May Macheny


